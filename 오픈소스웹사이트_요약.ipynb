{"cells":[{"cell_type":"markdown","metadata":{"id":"L0B1n20t-Ds8"},"source":["load_summarize_chain 라이브러리 모듈로 쉽게 요약하는 방법을 사용했다."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20392,"status":"ok","timestamp":1703335341624,"user":{"displayName":"이세훈","userId":"12770500502531488854"},"user_tz":-540},"id":"-SUNDUamqJIi","outputId":"0d7d92f1-044e-40cf-f3c5-db1030f9dec2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting langchain\n","  Downloading langchain-0.0.352-py3-none-any.whl (794 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.4/794.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting langchain-community<0.1,>=0.0.2 (from langchain)\n","  Downloading langchain_community-0.0.6-py3-none-any.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-core<0.2,>=0.1 (from langchain)\n","  Downloading langchain_core-0.1.3-py3-none-any.whl (192 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langsmith<0.1.0,>=0.0.70 (from langchain)\n","  Downloading langsmith-0.0.75-py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (3.7.1)\n","Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.2)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.2.0)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n","Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.352 langchain-community-0.0.6 langchain-core-0.1.3 langsmith-0.0.75 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"]}],"source":["!pip install langchain"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12723,"status":"ok","timestamp":1703335354340,"user":{"displayName":"이세훈","userId":"12770500502531488854"},"user_tz":-540},"id":"7LrbAwfhpxBD","outputId":"f5ef3595-f304-434f-b00a-5d2dd6982433"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tiktoken\n","  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n","Installing collected packages: tiktoken\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tiktoken-0.5.2\n"]}],"source":["!pip install tiktoken"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1703335354341,"user":{"displayName":"이세훈","userId":"12770500502531488854"},"user_tz":-540},"id":"bW9UDfqrqTW0"},"outputs":[],"source":["import os\n","\n","# 허깅페이스 LLM Read Key\n","# 이전 단계에서 복사한 Key를 아래에 붙혀넣기 합니다.\n","os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'YOUR HUGGINGFACEHUB_API_TOKEN'"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10725,"status":"ok","timestamp":1703335365061,"user":{"displayName":"이세훈","userId":"12770500502531488854"},"user_tz":-540},"id":"PgLKv5C5qoL-","outputId":"d8b19a53-d738-4e24-f9f0-1781a92e4d51"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting python-dotenv\n","  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n","Installing collected packages: python-dotenv\n","Successfully installed python-dotenv-1.0.0\n"]}],"source":["!pip install python-dotenv"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1703335365062,"user":{"displayName":"이세훈","userId":"12770500502531488854"},"user_tz":-540},"id":"PTqkf1HurEGj","outputId":"5f2cee55-e109-4362-8cbd-2f23a594c8b9"},"outputs":[{"data":{"text/plain":["False"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from dotenv import load_dotenv\n","load_dotenv()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1770,"status":"ok","timestamp":1703335509733,"user":{"displayName":"이세훈","userId":"12770500502531488854"},"user_tz":-540},"id":"Ufq29o8SopHx","outputId":"059aca89-9d64-4588-8cb5-98e8c8f52496"},"outputs":[{"data":{"text/plain":["[Document(page_content='랭체인(LangChain)이란 무엇인가? | 인사이트리포트 | 삼성SDS\\n\\n\\n \\n\\n\\n본문 바로가기\\n\\n\\n인사이트 리포트/상세 기사\\n\\n\\nloading...\\n\\n인공지능\\n랭체인(LangChain)이란 무엇인가?\\n\\n2023-09-18\\nJanakiram MSV\\n\\n\\nJanakiram MSV\\n\\n\\n인쇄하기\\n\\n\\n이 글은 IDG의 아티클을 전재하여 제공합니다.\\n[원문보기] : https://www.ciokorea.com/column/305341\\n\\n랭체인(LangChain)은 노출하여 대규모 언어 모델과 애플리케이션의 통합을 간소화하는 SDK이다. 대규모 언어 모델의 부상과 함께 중요성이 커지고 있다. 대규모 언어 모델에 대한 최신 트렌드를 쫓는 소프트웨어 개발자라면 연일 쏟아지는 소식이 당황스러울 수 있다. 새로운 오픈소스 모델의 출시나 상용 모델 제공업체의 중요한 새 기능 발표가 매일 등장하는 상황과 비슷하다고 할 수 있다.\\n\\n어느덧 LLM은 최신 소프트웨어 스택의 한 요소로 빠르게 부상했다. 그러나 오픈AI와 같은 공급업체가 제공하는 모델 API를 사용하든, 오픈소스 모델을 앱에 포함하든 LLM 기반 애플리케이션을 구축하려면 단순히 프롬프트를 보내고 응답을 기다리는 것 이상의 작업이 필요하다. 매개변수 조정부터 프롬프트 보강, 응답 조정에 이르기까지 고려해야 할 요소가 많다. 이를테면 LLM은 상태를 저장하지 않으므로 대화의 이전 메시지를 기억하지 못한다. 기록을 유지하고 LLM에 컨텍스트를 제공하는 것은 개발자의 책임이다. 맥락 정보가 새로운 대화에서 컨텍스트를 다시 가져오기 위해 영구 데이터베이스에 저장되어야 할 수도 있다. 이렇듯 LLM에 단기 및 장기 메모리를 추가하는 것은 개발자의 주요 책임 중 하나이다. 또 다른 문제는 LLM에 대한 일률적인 규칙이 없다는 것이다. 감정 분석, 분류, 질문 답변과 요약 등 다양한 시나리오에 특화된 여러 모델을 사용해야 할 수 있다. 여러 LLM을 처리하는 작업은 복잡하며 상당한 노력을 필요로 한다.\\n\\nLLM 앱을 구축하기 위한 통합 API 레이어\\n\\n랭체인은 LLM과 애플리케이션의 통합을 간소화하도록 설계된 SDK로서 앞서 설명한 대부분의 문제를 해결한다. 랭체인은 ODBC, 또는 표준 SQL 문에 집중하게 함으로써 백엔드 데이터베이스의 구현 세부 정보를 요약하는 JDBC 드라이버와 비슷하다고 할 수 있다. 랭체인은 간단하고 통합된 API를 노출하여 기본 LLM의 구현 세부 사항을 요약하는데, 이 API를 통해 개발자들은 코드를 크게 변경하지 않고 모델을 쉽게 교체하거나 대체할 수 있다.\\n\\n랭체인은 챗GPT와 거의 같은 시기에 등장했다. 개발자인 해리슨 체이스는 2022년 10월 말, LLM 열풍이 일어나기 시작한 시점에 랭체인을 처음 선보였다. 그 이후로 커뮤니티 구성원들이 적극적으로 기여했으며, 이로 인해 랭체인은 LLM과 상호 작용하는 탁월한 도구로 부상했다. 랭체인은 외부 도구와 통합되어 환경을 조성하는 강력한 프레임워크이다. 이제 이 프레임워크가 어떻게 LLM에서 원하는 결과를 얻기 위한 흐름을 조율하는지 살펴본다.\\n\\ndata sources ↔①\\nword embeddings↔②\\nvector database↔③\\n\\nLangChain\\n\\nfetch external data\\ngenerate word embeddings\\nstore and retrieve vectors\\nsend prompt and retrieve response\\n\\n\\nLarge Language Models↔④\\n\\n\\n[그림 1] 랭체인 흐름도\\n\\n①\\xa0 데이터 소스\\n\\n애플리케이션이 LLM에 대한 컨텍스트를 구축하기 위해 PDF, 웹 페이지, CSV, 관계형 데이터베이스와 같은 외부 소스에서 데이터를 검색해야 하는 경우가 있다. 랭체인은 서로 다른 소스에서 데이터에 액세스하고 검색할 수 있는 모듈과 원활하게 통합된다.\\n②\\xa0 단어 임베딩\\n\\n일부 외부 소스에서 검색된 데이터는 벡터로 변환되어야 한다. 그래야 텍스트를 LLM과 관련된 단어 임베딩 모델에 전달하게 된다. 실제로 오픈AI의 GPT-3.5 모델은 컨텍스트를 전송하는 데 사용해야 하는 단어 임베딩 모델과 관련되어 있다. 랭체인은 선택한 LLM을 기반으로 최적의 임베딩 모델을 선택한다.\\n\\n③\\xa0 벡터 데이터베이스\\n\\n생성된 임베딩은 유사성 검색을 위해 벡터 데이터베이스에 저장된다. 랭체인은 메모리 내 배열부터 파인콘(Pinecone)과 같은 호스팅 벡터 데이터베이스에 이르기까지 다양한 소스에서 벡터를 쉽게 저장하고 검색할 수 있도록 지원한다.\\n\\n④\\xa0 언어 모델(LLM)\\n\\n랭체인은 오픈AI, 코히어(Cohere), AI21에서 제공하는 주류 LLM과 허깅페이스(Hugging Face)에서 제공되는 오픈소스 LLM을 지원한다. 지원되는 모델과 API 엔드포인트 목록은 빠르게 증가하고 있다.\\n\\n[그림 2]는 랭체인 프레임워크의 핵심을 나타낸다. 스택 상단의 애플리케이션은 파이썬 또는 자바스크립트 SDK를 통해 여러 랭체인 모듈 중 하나와 상호 작용한다. 여러 모듈의 역할을 살펴보면 다음과 같다.\\n\\n\\napplication\\n\\nvector database\\ndata sources\\n\\n\\nAgents\\nMemory\\nCallbacks\\nData Connection\\nChains\\nMedel I/O\\n\\n\\nLangChain Framework\\n\\n\\nWord Embeddings\\nLLarge Language Models\\n\\n\\n[그림 2] 랭체인 프레임워크\\n\\n에이전트\\n\\n에이전트는 랭체인에서 아주 강력한 모듈이다. LLM은 추론과 행동이 가능한데, 이는 ReAct 프롬프트 기법이라고 불린다. 랭체인의 에이전트는 LLM을 사용하여 프롬프트를 행동 계획으로 추출하는 ReAct 프롬프트 제작을 단순화한다. 에이전트는 일종의 동적 체인으로 생각할 수 있다. 에이전트의 기본 일련의 동작을 선택하기 위해 LLM을 사용하는 것이다. 동작의 순서는 체인(코드)으로 하드 코딩된다. 언어 모델은 에이전트 내에서 추론 엔진으로 사용되어 어떤 순서로 어떤 동작을 취할지 결정한다.\\n\\n메모리', metadata={'source': 'https://www.samsungsds.com/kr/insights/what-is-langchain.html', 'title': '랭체인(LangChain)이란 무엇인가? | 인사이트리포트 | 삼성SDS', 'description': '랭체인(LangChain)은 노출하여 대규모 언어 모델과 애플리케이션의 통합을 간소화하는 SDK입니다. 대규모 언어 모델의 부상과 함께 중요성이 커지고 있다. 대규모 언어 모델에 대한 최신 트렌드를 쫓는 소프트웨어 개발자라면 연일 쏟아지는 소식이 당황스러울 수 있습니다. 새로운 오픈소스 모델의 출시나 상용 모델 제공업체의 중요한 새 기능 발표가 매일 등장하는 상황과 비슷하다고 할 수 있습니다.', 'language': 'ko'}),\n"," Document(page_content=\"에이전트\\n\\n에이전트는 랭체인에서 아주 강력한 모듈이다. LLM은 추론과 행동이 가능한데, 이는 ReAct 프롬프트 기법이라고 불린다. 랭체인의 에이전트는 LLM을 사용하여 프롬프트를 행동 계획으로 추출하는 ReAct 프롬프트 제작을 단순화한다. 에이전트는 일종의 동적 체인으로 생각할 수 있다. 에이전트의 기본 일련의 동작을 선택하기 위해 LLM을 사용하는 것이다. 동작의 순서는 체인(코드)으로 하드 코딩된다. 언어 모델은 에이전트 내에서 추론 엔진으로 사용되어 어떤 순서로 어떤 동작을 취할지 결정한다.\\n\\n메모리\\n\\nLLM은 상태 비저장형이지만 정확한 응답을 위해 컨텍스트가 필요하다. 랭체인의 메모리 모듈은 모델에 단기 및 장기 메모리를 쉽게 추가할 수 있도록 도와준다. 단기 메모리는 간단한 메커니즘을 통해 대화의 기록을 유지한다. 메시지 기록은 레디스(Redis)와 같은 외부 소스에 저장되어 장기 메모리를 유지할 수 있다.\\n\\n콜백\\n\\n랭체인은 개발자에게 LLM 애플리케이션의 다양한 단계에 연결할 수 있는 콜백 시스템을 제공한다. 이는 로깅, 모니터링, 스트리밍 및 기타 작업에 유용하다. 파이프라인 내에서 특정 상황이 발생할 때 호출되는 사용자 지정 콜백 핸들러를 작성할 수 있게 해준다. 랭체인의 기본 콜백은 모든 단계의 출력을 콘솔에 간단히 인쇄하는 stdout을 가리킨다.\\n\\n데이터 연결\\n\\n데이터 연결 모듈을 LLM 애플리케이션의 ETL 파이프라인에 해당한다. 이 모듈은 PDF 또는 엑셀 파일과 같은 외부 문서를 로드하고, 이를 처리하기 위해 일괄적으로 단어 임베딩으로 변환한 다음, 임베딩을 벡터 데이터베이스에 저장하고, 마지막으로 쿼리를 통해 검색한다. 앞서 설명한 바와 같이, 이는 랭체인의 가장 중요한 구성 요소이다.\\n\\n체인\\n\\nLLM과 상호 작용하는 것은 유닉스 파이프라인을 사용하는 것과 많은 면에서 유사하다. 한 모듈의 출력이 다른 모듈에 입력으로 전송된다. 개발자는 종종 원하는 결과를 얻을 때까지 LLM을 사용해 응답을 명확하게 하고 요약해야 한다. 랭체인의 체인은 구성 요소와 LLM을 활용하여 예상되는 응답을 얻는 효율적인 파이프라인을 구축하도록 설계됐다. 간단한 체인에는 프롬프트와 LLM이 포함될 수 있지만 재귀와 같이 LLM을 여러 번 호출하여 결과를 얻는 등 매우 복잡한 체인을 구축할 수도 있다. 예를 들어, 체인은 문서를 요약한 다음 이에 대한 감정 분석을 수행하는 프롬프트가 포함될 수 있다.\\n\\n모델 I/O\\n\\n모델 I/O 모듈은 LLM과의 상호 작용을 다룬다. 이는 기본적으로 효과적인 프롬프트를 생성하고, 모델 API를 호출하고, 결과 해석을 돕는다. 생성형 AI의 핵심인 프롬프트 엔지니어링이 랭체인에서 잘 처리된다. 이 모듈은 LLM 제공자가 노출하는 인증, API 매개변수, 엔드포인트를 요약한다. 이 모듈은 마지막으로, 모델에서 보낸 응답을 애플리케이션서 사용할 수 있는 원하는 형식으로 해석하는 작업을 돕는다.\\n\\n어느덧 랭체인은 생성형 AI 기반 애플리케이션에서 중요한 구성 요소로 빠르게 자리 잡고 있다. 계속해서 발전 중인 환경 덕분에 다양한 구성 요소를 지원할 수 있다. 오픈소스 및 상용 LLM, 벡터 데이터베이스, 데이터 소스 및 임베딩에 대한 지원은 랭체인을 개발자에게 필수적인 도구로 만들고 있다.\\n\\n\\n  \\n▶\\xa0\\xa0 해당 콘텐츠는 저작권법에 의하여 보호받는 저작물로 기고자에게 저작권이 있습니다.\\n▶\\xa0\\xa0 해당 콘텐츠는 사전 동의 없이 2차 가공 및 영리적인 이용을 금하고 있습니다.\\n\\n#인공지능\\n#AI\\n#랭체인\\n#LangChain\\n#생성형AI\\n#GenerativeAI\\n#언어모델\\n#LLM\\n#벡터데이터베이스\\n\\n이 글이 좋으셨다면 구독&좋아요\\n여러분의 “구독”과 “좋아요”는 저자에게 큰 힘이 됩니다.\\n\\n구독하기\\n\\n\\n좋아요\\n\\n\\nJanakiram MSV\\n\\n\\nInfoWorld\\n모든 글보기\\n\\n<목록보기\\n\\n\\n뉴스레터 구독신청\\n\\n\\n관련 아티클\\n\\n\\n글로벌 AI 리더들이 전하는 생성형 AI 기술의 전망\\n\\n\\n'생성형 AI 중심'으로 변화하는 B2B 기업\\n\\n\\n기업의 업무 자동화 RPA, LLM으로 환골탈태하다\\n\\n\\n생성형 AI 모델과 대화하는 프롬프트 엔지니어링(Prompt Engineering)\\n\\n\\n웹, 앱에서 생성형 AI로 인터넷의 진화\\n\\n공유하기\\n\\n\\nLinkedin\\n\\nFacebook\\n\\nTwitter\\n\\n카카오톡\\n\\n공유하기 닫기\", metadata={'source': 'https://www.samsungsds.com/kr/insights/what-is-langchain.html', 'title': '랭체인(LangChain)이란 무엇인가? | 인사이트리포트 | 삼성SDS', 'description': '랭체인(LangChain)은 노출하여 대규모 언어 모델과 애플리케이션의 통합을 간소화하는 SDK입니다. 대규모 언어 모델의 부상과 함께 중요성이 커지고 있다. 대규모 언어 모델에 대한 최신 트렌드를 쫓는 소프트웨어 개발자라면 연일 쏟아지는 소식이 당황스러울 수 있습니다. 새로운 오픈소스 모델의 출시나 상용 모델 제공업체의 중요한 새 기능 발표가 매일 등장하는 상황과 비슷하다고 할 수 있습니다.', 'language': 'ko'})]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["from langchain.chat_models import ChatOpenAI\n","from langchain.document_loaders import WebBaseLoader\n","from langchain.text_splitter import CharacterTextSplitter\n","from langchain.chains.summarize import load_summarize_chain\n","from langchain.prompts import PromptTemplate\n","from langchain.llms import HuggingFaceHub\n","\n","url ='https://www.samsungsds.com/kr/insights/what-is-langchain.html'\n","\n","loader = WebBaseLoader(url)\n","\n","text_splitter = CharacterTextSplitter(\n","    separator=\"\\n\\n\",\n","    chunk_size=3000,\n","    chunk_overlap=300,\n","    length_function=len,\n","    is_separator_regex=False,\n",")\n","\n","docs = WebBaseLoader(url).load_and_split(text_splitter)\n","docs"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5958,"status":"ok","timestamp":1703335555726,"user":{"displayName":"이세훈","userId":"12770500502531488854"},"user_tz":-540},"id":"WJ64eF1qpfXL","outputId":"cdc5916d-3224-47ee-8b09-c51ebfb3514b"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n","  warnings.warn(warning_message, FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","\n","랭체인은 랭체인 프레임워크를 통해 랭체인 기반 생성형 AI 앱을 구축하는 데 필요한 기술을 제공합니다. 랭체인은 랭체인 프레임워크를 통해 랭체인 \n"]}],"source":["chain = load_summarize_chain(chain_type=\"stuff\",\n","                        llm=HuggingFaceHub(repo_id = 'mistralai/Mistral-7B-Instruct-v0.1',\n","                                                      model_kwargs={\"temperature\": 0.1,\n","                                                     \"max_length\": 256}))\n","\n","# 실행결과\n","print(chain.run(docs))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP/CTv/UydMVFXBhBdwpJQu","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
